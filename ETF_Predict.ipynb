{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ylieo816/US-Stock-Investion-Calculator/blob/main/ETF_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxd0XvLiFhMY"
      },
      "source": [
        "## **Basic Info**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4f_JjMTMDTi"
      },
      "source": [
        "Make a copy for the following sheet on you google drive and edit that copyed file (DO NOT EDIT FILE NAME):\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1CJCSn11gKZ2P7JkRzmSoizO--zyscO-s/edit?usp=sharing&ouid=110680874934690356046&rtpof=true&sd=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qcz73lPFWxyD"
      },
      "source": [
        "## **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE9cw_SiW14B"
      },
      "source": [
        "Please view the same file for the results (File in your Google Drive, Copyed File)\n",
        "\n",
        "Other Sheets Explaination (After Excution the Program):\n",
        "\n",
        "### auto re-balance output:\n",
        "- Offers a detailed breakdown for each asset, showcasing its current price and the number of shares to buy or sell post-rebalancing.\n",
        "\n",
        "### Extra Detail:\n",
        "- Provides insights into individual assets and presents a comprehensive summary for each asset as well as an aggregate summary for all assets combined.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCGtJxp5Wd6i"
      },
      "source": [
        "## **CODE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkV7ogEuX0dI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d58741-dcc4-457d-cec3-52d1592c216a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Mounted at /content/drive\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.28)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.3\n",
            "Collecting numpy_financial\n",
            "  Downloading numpy_financial-1.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from numpy_financial) (1.23.5)\n",
            "Installing collected packages: numpy_financial\n",
            "Successfully installed numpy_financial-1.0.0\n",
            "Collecting yagmail\n",
            "  Downloading yagmail-0.15.293-py2.py3-none-any.whl (17 kB)\n",
            "Collecting premailer (from yagmail)\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from premailer->yagmail) (4.9.3)\n",
            "Collecting cssselect (from premailer->yagmail)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cssutils (from premailer->yagmail)\n",
            "  Downloading cssutils-2.7.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from premailer->yagmail) (2.31.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->yagmail) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->yagmail) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->yagmail) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->yagmail) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->yagmail) (2023.7.22)\n",
            "Installing collected packages: cssutils, cssselect, premailer, yagmail\n",
            "Successfully installed cssselect-1.2.0 cssutils-2.7.1 premailer-3.10.0 yagmail-0.15.293\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install yfinance\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install numpy_financial\n",
        "!pip install yagmail\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94OMi-xckgUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c849a4-3a28-4448-c3fd-e0a46846617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.03, 0.1, 0.01, 0.01, 0.05, 0.01, 0.0829, 0.01, 0.03, 0.02, 0.01, 0.03, 0.3, 0.2971, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
            "[3.01, 6.01, 5.01, 3.01, 0.0, 6.01, 9.02, 0, 0, 0, 0, 0, 0, 0, 0, 3.01, 0.0, 1.0, 5.02]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import display, Javascript\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.styles import Alignment\n",
        "\n",
        "def alert(message):\n",
        "    display(Javascript(f'alert(\"{message}\")'))\n",
        "\n",
        "def center_content_in_sheet(workbook, sheet_name):\n",
        "    ws = workbook[sheet_name]\n",
        "    for row in ws.iter_rows():\n",
        "        for cell in row:\n",
        "            cell.alignment = Alignment(horizontal='center', vertical='center')\n",
        "\n",
        "errors = []  # List to collect errors\n",
        "\n",
        "# Load the data from the Excel file\n",
        "df = pd.read_excel('/content/drive/My Drive/Previous_ETF_Record.xlsx', sheet_name='auto re-balance input')\n",
        "\n",
        "# Load the workbook\n",
        "wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'ETF Prediction' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['ETF Prediction'])\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'Shares To Buy' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['Shares To Buy'])\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'Performance' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['Performance'])\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'Error' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['Error'])\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'auto re-balance output' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['auto re-balance output'])\n",
        "\n",
        "# Check if the sheet exists\n",
        "if 'Extra Detail' in wb.sheetnames:\n",
        "    # If it exists, remove it\n",
        "    wb.remove(wb['Extra Detail'])\n",
        "\n",
        "# Save the workbook\n",
        "wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "\n",
        "# Save the workbook\n",
        "wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "# Check that the required columns exist\n",
        "required_columns = ['Symbol', 'Weight Allocation', 'Pre-txn Quantity (交易前數量)', 'Investment Budget (USD) (賣出-/投資+)']\n",
        "for column in required_columns:\n",
        "    if column not in df.columns:\n",
        "        errors.append(f\"Missing required column: {column}\")\n",
        "\n",
        "# Set the variables based on the data in the DataFrame\n",
        "symbols_list = df['Symbol'].tolist()\n",
        "distribution = df['Weight Allocation'].tolist()\n",
        "current_ETF_shares = df['Pre-txn Quantity (交易前數量)'].tolist()\n",
        "# last_investment_date = '2023-04-04 00:00:00'\n",
        "original_amount_available = df['Investment Budget (USD) (賣出-/投資+)'].iloc[0]\n",
        "\n",
        "# Convert the lists to contain float values\n",
        "distribution = [float(x) for x in distribution]\n",
        "current_ETF_shares = [0 if np.isnan(x) else float(x) for x in current_ETF_shares]\n",
        "\n",
        "# Convert original_amount_available to float\n",
        "original_amount_available = float(original_amount_available)\n",
        "\n",
        "print(distribution)\n",
        "\n",
        "# Check that the distributions add up to 1 (allowing for a small error)\n",
        "if not np.isclose(sum(distribution), 1, atol=0.001):\n",
        "    errors.append(\"The total weights do not add up to 1 or 100%.\")\n",
        "\n",
        "# Check that there are no negative values\n",
        "if any(x < 0 for x in current_ETF_shares):\n",
        "    errors.append(\"The current ETF shares contain negative values.\")\n",
        "\n",
        "# Define the investment dates 2023, investing on the first business day of each quarter\n",
        "dates_list = pd.date_range(start = pd.to_datetime('today').strftime('%Y-%m-%d'), end = pd.to_datetime('today').strftime('%Y-%m-%d')).strftime('%Y-%m-%d').tolist()\n",
        "dates_list.insert(0, \"2023-10-01\")\n",
        "dates_list = [pd.to_datetime(date).date() for date in dates_list]\n",
        "\n",
        "# Initialize an empty DataFrame with dates as the index\n",
        "price_data = pd.DataFrame(index=pd.to_datetime(dates_list))\n",
        "url = \"https://www.x-rates.com/calculator/?from=TWD&to=USD&amount=1\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "rate = soup.find_all('span', {'class': 'ccOutputTrail'})[0].previous_sibling\n",
        "TWD_USD_rate = float(rate)\n",
        "\n",
        "# Fetch the historical price data for each symbol and add it to the DataFrame\n",
        "for symbol in symbols_list:\n",
        "    # Fetch the historical price data\n",
        "    try:\n",
        "        tickerData = yf.Ticker(symbol)\n",
        "        tickerDf = tickerData.history(period='1d')\n",
        "\n",
        "        # Convert the index of tickerDf to a timezone-naive datetime index\n",
        "        tickerDf.index = tickerDf.index.tz_convert(None)\n",
        "\n",
        "        if symbol == '0050.TW':\n",
        "            price_data[symbol] = tickerDf['Close'].reindex(price_data.index, method='ffill') * TWD_USD_rate\n",
        "            # Update the last row with the current price\n",
        "            price_data.loc[price_data.index[-1], symbol] = tickerDf['Close'].iloc[-1] * TWD_USD_rate\n",
        "        else:\n",
        "            price_data[symbol] = tickerDf['Close'].reindex(price_data.index, method='ffill')\n",
        "            # Update the last row with the current price\n",
        "            price_data.loc[price_data.index[-1], symbol] = tickerDf['Close'].iloc[-1]\n",
        "    except Exception as e:\n",
        "        errors.append(f\"An error occurred while fetching data for {symbol}. Please double check if the {symbol} exists.\")\n",
        "\n",
        "# price_data.index = pd.to_datetime(price_data.index)\n",
        "price_data.index = price_data.index.date\n",
        "price_data.index.name = 'Date'\n",
        "\n",
        "# Remove the row for \"2023-01-01\" from price_data if it exists\n",
        "if pd.Timestamp(\"2023-01-01\").date() in price_data.index:\n",
        "    price_data = price_data.drop(pd.Timestamp(\"2023-01-01\"))\n",
        "\n",
        "hi = dates_list.pop(0)\n",
        "print(current_ETF_shares)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import brentq\n",
        "\n",
        "def calculate_difference(amount_available):\n",
        "  curr_value = 0\n",
        "  # Initialize a dictionary to hold the data for this date\n",
        "  date_data = {'Date': pd.to_datetime('today').strftime('%Y-%m-%d')}\n",
        "  predict_data = {'Date': []}\n",
        "  predict_data['Symbol'] = []\n",
        "  predict_data['Desired Value'] = []\n",
        "  predict_data['Price'] = []\n",
        "  predict_data['Shares Before'] = []\n",
        "  predict_data['Total Value Before'] = []\n",
        "  predict_data['Amount to Invest'] = []\n",
        "  predict_data['Shares to Buy'] = []\n",
        "  predict_data['Shares After'] = []\n",
        "  date_tem = date_data['Date']\n",
        "\n",
        "  for z in range(len(symbols_list)):\n",
        "      # Get the current symbol and distribution\n",
        "      symbol = symbols_list[z]\n",
        "\n",
        "      # Get the current price and number of shares owned before rebalancing\n",
        "      price = price_data.loc[date, symbol]\n",
        "      if i == 0:\n",
        "          shares_before = 0\n",
        "      else:\n",
        "          shares_before = current_ETF_shares[z]\n",
        "\n",
        "      # Calculate the total value before rebalancing\n",
        "      if symbol == '0050.TW':\n",
        "          curr_total_value = price * shares_before * 1\n",
        "      else:\n",
        "          curr_total_value = price * shares_before\n",
        "      # Sum up\n",
        "      curr_value +=  curr_total_value\n",
        "\n",
        "  total_amount = amount_available + curr_value\n",
        "\n",
        "  # Iterate over each ETF or Bond\n",
        "  for j in range(len(symbols_list)):\n",
        "      # Get the current symbol and distribution\n",
        "      symbol = symbols_list[j]\n",
        "      dist = distribution[j]\n",
        "      date_tem = pd.to_datetime(date)\n",
        "\n",
        "      # Calculate the desired value\n",
        "      desired_value = total_amount * dist\n",
        "\n",
        "      # Get the current price and number of shares owned before rebalancing\n",
        "      price = price_data.loc[date, symbol]\n",
        "      if i == 0:\n",
        "          shares_before = 0\n",
        "      else:\n",
        "          shares_before = float(current_ETF_shares[j])\n",
        "\n",
        "      # Calculate the total value before rebalancing\n",
        "      if symbol == '0050.TW':\n",
        "          total_value_before = price * shares_before * 1\n",
        "      else:\n",
        "          total_value_before = price * shares_before\n",
        "\n",
        "      # Calculate the amount to invest (or redeem)\n",
        "      amount_to_invest = desired_value - total_value_before\n",
        "\n",
        "\n",
        "      # Calculate shares to buy as before\n",
        "      if symbol == '0050.TW':\n",
        "          shares_to_buy = round(amount_to_invest / (price * 1))\n",
        "      else:\n",
        "          shares_to_buy = round(amount_to_invest / price)\n",
        "\n",
        "      # Ensure that we're not trying to sell more shares than we own\n",
        "      if shares_to_buy < 0 and -shares_to_buy > shares_before:\n",
        "          # print('here')\n",
        "          shares_to_buy = -int(shares_before)\n",
        "\n",
        "\n",
        "      # Calculate the number of shares owned after rebalancing\n",
        "      shares_after = float(shares_before + shares_to_buy)\n",
        "\n",
        "      # Add the calculations to the dictionary\n",
        "      date_data[f'{symbol} Desired Value'] = desired_value\n",
        "      date_data[f'{symbol} Price'] = price\n",
        "      date_data[f'{symbol} Shares Before'] = shares_before\n",
        "      date_data[f'{symbol} Total Value Before'] = total_value_before\n",
        "      date_data[f'{symbol} Amount to Invest'] = amount_to_invest\n",
        "      date_data[f'{symbol} Shares to Buy'] = shares_to_buy\n",
        "      date_data[f'{symbol} Shares After'] = shares_after\n",
        "\n",
        "      predict_data['Date'].append(pd.to_datetime('today').strftime('%Y-%m-%d'))\n",
        "      predict_data['Symbol'].append(symbol)\n",
        "      predict_data['Desired Value'].append(desired_value)\n",
        "      predict_data['Price'].append(price)\n",
        "      predict_data['Shares Before'].append(shares_before)\n",
        "      predict_data['Total Value Before'].append(total_value_before)\n",
        "      predict_data['Amount to Invest'].append(amount_to_invest)\n",
        "      predict_data['Shares to Buy'].append(shares_to_buy)\n",
        "      predict_data['Shares After'].append(shares_after)\n",
        "\n",
        "  # Calculate actual_invest_amount\n",
        "  actual_invest_amount = 0\n",
        "  for j in range(len(symbols_list)):\n",
        "      # Get the current symbol\n",
        "      symbol = symbols_list[j]\n",
        "\n",
        "      # Get the current price and number of shares to buy\n",
        "      price = price_data.loc[date, symbol]\n",
        "      shares_to_buy = date_data[f'{symbol} Shares to Buy']  # Use date instead of i\n",
        "\n",
        "      # Calculate the value\n",
        "      value = 0\n",
        "      if symbol == '0050.TW':\n",
        "          value = price * shares_to_buy * 1\n",
        "      else:\n",
        "         value = shares_to_buy * price\n",
        "      actual_invest_amount += value\n",
        "  calculate_difference.date_data = date_data\n",
        "  calculate_difference.predict_data = predict_data\n",
        "  calculate_difference.actual_invest_amount= actual_invest_amount\n",
        "  calculate_difference.difference = actual_invest_amount - original_amount_available\n",
        "  return actual_invest_amount - original_amount_available\n",
        "\n",
        "\n",
        "#####################\n",
        "##Rebalancing Start##\n",
        "#####################\n",
        "\n",
        "amount_available = original_amount_available\n",
        "\n",
        "date = dates_list[-1]\n",
        "\n",
        "if (len(errors) == 0):\n",
        "\n",
        "    # Calculate the total value of the portfolio\n",
        "    total_portfolio_value = sum(price_data.loc[date, symbol] * shares for symbol, shares in zip(symbols_list, current_ETF_shares))\n",
        "\n",
        "    # Check that the user is not trying to sell more than they own\n",
        "    if original_amount_available < -total_portfolio_value:\n",
        "        errors.append(f\"You are trying to sell more than you currently own.\")\n",
        "\n",
        "# Initialize the best result\n",
        "best_result = None\n",
        "best_difference = float('inf')\n",
        "best_predict_data = None\n",
        "best_date_data = None\n",
        "i = 1\n",
        "date_data = None\n",
        "best_date_data = None\n",
        "\n",
        "# Set a tolerance for the difference\n",
        "tolerance = 1e-6\n",
        "\n",
        "if (len(errors) == 0):\n",
        "\n",
        "    # Run the initial amount\n",
        "    amount_available = original_amount_available\n",
        "    difference = calculate_difference(amount_available)\n",
        "\n",
        "    # If the difference is negative, increment the amount\n",
        "    if difference < 0:\n",
        "        # Initialize a counter for the number of consecutive decreases\n",
        "        decrease_counter = 0\n",
        "\n",
        "        while True:\n",
        "            # Increment the amount\n",
        "            amount_available += 1\n",
        "\n",
        "            # Calculate the new difference\n",
        "            new_difference = calculate_difference(amount_available)\n",
        "\n",
        "            # If this result is better than the current best result, update the best result\n",
        "            if abs(new_difference) < best_difference:\n",
        "                best_difference = abs(new_difference)\n",
        "                best_result = calculate_difference.actual_invest_amount\n",
        "                best_predict_data = calculate_difference.predict_data\n",
        "                best_date_data = calculate_difference.date_data\n",
        "\n",
        "            # If the new difference is less than the old difference, increment the counter\n",
        "            if new_difference > 0 :\n",
        "                decrease_counter += 1\n",
        "            else:\n",
        "                # If the new difference is not less than the old difference, reset the counter\n",
        "                decrease_counter = 0\n",
        "\n",
        "            # If the new difference is close to zero or the counter reaches a certain threshold, stop the loop\n",
        "            if abs(new_difference) < tolerance or decrease_counter >= 5:  # Change 5 to the number of consecutive decreases you want\n",
        "                break\n",
        "\n",
        "            # Update the difference\n",
        "            difference = new_difference\n",
        "\n",
        "    # If the difference is positive, decrement the amount\n",
        "    elif difference > 0:\n",
        "        # Initialize a counter for the number of consecutive decreases\n",
        "        decrease_counter = 0\n",
        "\n",
        "        while True:\n",
        "            # Decrement the amount\n",
        "            amount_available -= 1\n",
        "\n",
        "            # Calculate the new difference\n",
        "            new_difference = calculate_difference(amount_available)\n",
        "            # If this result is better than the current best result, update the best result\n",
        "            if abs(new_difference) < best_difference:\n",
        "                best_difference = abs(new_difference)\n",
        "                best_result = calculate_difference.actual_invest_amount\n",
        "                best_predict_data = calculate_difference.predict_data\n",
        "                best_date_data = calculate_difference.date_data\n",
        "\n",
        "            # If the new difference is less than the old difference, increment the counter\n",
        "            if new_difference < 0:\n",
        "                decrease_counter += 1\n",
        "            else:\n",
        "                # If the new difference is not less than the old difference, reset the counter\n",
        "                decrease_counter = 0\n",
        "\n",
        "            # If the new difference is close to zero or the counter reaches a certain threshold, stop the loop\n",
        "            if abs(new_difference) < tolerance or decrease_counter >= 5:  # Change 5 to the number of consecutive decreases you want\n",
        "                break\n",
        "\n",
        "            # Update the difference\n",
        "            difference = new_difference\n",
        "\n",
        "    # Access updated date_data\n",
        "    iter_date_data = best_predict_data\n",
        "    iter_best_date_data = best_date_data\n",
        "    iter_best_difference = best_difference\n",
        "\n",
        "    # Print the best result\n",
        "    print(f\"The best result with iteration is: {best_result}\")\n",
        "\n",
        "\n",
        "    from scipy.optimize import root_scalar\n",
        "\n",
        "    # Use the difference from your iterative method as the tolerance\n",
        "    tolerance = iter_best_difference\n",
        "\n",
        "    # Check the signs of the function at the endpoints of the bracket\n",
        "    fa = calculate_difference(0)\n",
        "    fb = calculate_difference(original_amount_available * 1.5)\n",
        "\n",
        "    if np.sign(fa) == np.sign(fb):\n",
        "        date_data = iter_date_data\n",
        "        best_date_data = iter_best_date_data\n",
        "\n",
        "    else:\n",
        "        _ = root_scalar(calculate_difference, method='brentq', bracket=[0, original_amount_available * 1.5], xtol=tolerance)\n",
        "        brentq_date_data = calculate_difference.predict_data\n",
        "        brentq_best_date_data = calculate_difference.date_data\n",
        "        brentq_best_difference = calculate_difference.difference\n",
        "\n",
        "        # Print the best result\n",
        "        print(f\"The best result with brentq is: {calculate_difference.actual_invest_amount}\")\n",
        "\n",
        "        print(iter_best_difference , '  ', abs(brentq_best_difference))\n",
        "\n",
        "        if (iter_best_difference <= abs(brentq_best_difference)):\n",
        "            date_data = iter_date_data\n",
        "            best_date_data = iter_best_date_data\n",
        "        else:\n",
        "            date_data = brentq_date_data\n",
        "            best_date_data = brentq_best_date_data\n",
        "\n",
        "\n",
        "print(date_data)\n",
        "print(best_date_data)\n"
      ],
      "metadata": {
        "id": "Em9jE59l_vGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f7005e-bbd4-4ef9-cb13-94034b828402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best result with iteration is: 2041.9038734817505\n",
            "The best result with brentq is: 1994.5038719558715\n",
            "3.623873481750479    43.77612804412843\n",
            "{'Date': ['2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10', '2023-09-10'], 'Symbol': ['VEU', 'VTI', 'VB', 'VNQ', '0050.TW', 'VWO', 'VTIP', 'BND', 'VCIT', 'HYG', 'VGIT', 'VIG', 'VGT', 'XLV', 'ESGU', 'VGK', 'VSS', 'BSV', 'VCSH'], 'Desired Value': [181.77684603767392, 605.9228201255798, 60.59228201255798, 60.59228201255798, 302.9614100627899, 60.59228201255798, 502.31001788410566, 60.59228201255798, 181.77684603767392, 121.18456402511596, 60.59228201255798, 181.77684603767392, 1817.7684603767393, 1800.1966985930974, 60.59228201255798, 0.0, 0.0, 0.0, 0.0], 'Price': [53.22999954223633, 221.4199981689453, 196.25999450683594, 81.58000183105469, 3.8669730949401853, 40.20000076293945, 47.400001525878906, 71.0, 77.38999938964844, 74.62000274658203, 57.689998626708984, 161.39999389648438, 436.25, 132.05999755859375, 98.16999816894531, 59.59000015258789, 109.47000122070312, 75.30000305175781, 75.37000274658203], 'Shares Before': [3.01, 6.01, 5.01, 3.01, 0.0, 6.01, 9.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.01, 0.0, 1.0, 5.02], 'Total Value Before': [160.22229862213135, 1330.7341889953614, 983.262572479248, 245.5558055114746, 0.0, 241.60200458526612, 427.5480137634277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 179.36590045928955, 0.0, 75.30000305175781, 378.3574137878418], 'Amount to Invest': [21.554547415542572, -724.8113688697815, -922.67029046669, -184.96352349891663, 302.9614100627899, -181.00972257270814, 74.76200412067794, 60.59228201255798, 181.77684603767392, 121.18456402511596, 60.59228201255798, 181.77684603767392, 1817.7684603767393, 1800.1966985930974, 60.59228201255798, -179.36590045928955, 0.0, -75.30000305175781, -378.3574137878418], 'Shares to Buy': [0, -3, -5, -2, 78, -5, 2, 1, 2, 2, 1, 1, 4, 14, 1, -3, 0, -1, -5], 'Shares After': [3.01, 3.01, 0.009999999999999787, 1.0099999999999998, 78.0, 1.0099999999999998, 11.02, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 14.0, 1.0, 0.009999999999999787, 0.0, 0.0, 0.019999999999999574]}\n",
            "{'Date': '2023-09-10', 'VEU Desired Value': 181.77684603767392, 'VEU Price': 53.22999954223633, 'VEU Shares Before': 3.01, 'VEU Total Value Before': 160.22229862213135, 'VEU Amount to Invest': 21.554547415542572, 'VEU Shares to Buy': 0, 'VEU Shares After': 3.01, 'VTI Desired Value': 605.9228201255798, 'VTI Price': 221.4199981689453, 'VTI Shares Before': 6.01, 'VTI Total Value Before': 1330.7341889953614, 'VTI Amount to Invest': -724.8113688697815, 'VTI Shares to Buy': -3, 'VTI Shares After': 3.01, 'VB Desired Value': 60.59228201255798, 'VB Price': 196.25999450683594, 'VB Shares Before': 5.01, 'VB Total Value Before': 983.262572479248, 'VB Amount to Invest': -922.67029046669, 'VB Shares to Buy': -5, 'VB Shares After': 0.009999999999999787, 'VNQ Desired Value': 60.59228201255798, 'VNQ Price': 81.58000183105469, 'VNQ Shares Before': 3.01, 'VNQ Total Value Before': 245.5558055114746, 'VNQ Amount to Invest': -184.96352349891663, 'VNQ Shares to Buy': -2, 'VNQ Shares After': 1.0099999999999998, '0050.TW Desired Value': 302.9614100627899, '0050.TW Price': 3.8669730949401853, '0050.TW Shares Before': 0.0, '0050.TW Total Value Before': 0.0, '0050.TW Amount to Invest': 302.9614100627899, '0050.TW Shares to Buy': 78, '0050.TW Shares After': 78.0, 'VWO Desired Value': 60.59228201255798, 'VWO Price': 40.20000076293945, 'VWO Shares Before': 6.01, 'VWO Total Value Before': 241.60200458526612, 'VWO Amount to Invest': -181.00972257270814, 'VWO Shares to Buy': -5, 'VWO Shares After': 1.0099999999999998, 'VTIP Desired Value': 502.31001788410566, 'VTIP Price': 47.400001525878906, 'VTIP Shares Before': 9.02, 'VTIP Total Value Before': 427.5480137634277, 'VTIP Amount to Invest': 74.76200412067794, 'VTIP Shares to Buy': 2, 'VTIP Shares After': 11.02, 'BND Desired Value': 60.59228201255798, 'BND Price': 71.0, 'BND Shares Before': 0.0, 'BND Total Value Before': 0.0, 'BND Amount to Invest': 60.59228201255798, 'BND Shares to Buy': 1, 'BND Shares After': 1.0, 'VCIT Desired Value': 181.77684603767392, 'VCIT Price': 77.38999938964844, 'VCIT Shares Before': 0.0, 'VCIT Total Value Before': 0.0, 'VCIT Amount to Invest': 181.77684603767392, 'VCIT Shares to Buy': 2, 'VCIT Shares After': 2.0, 'HYG Desired Value': 121.18456402511596, 'HYG Price': 74.62000274658203, 'HYG Shares Before': 0.0, 'HYG Total Value Before': 0.0, 'HYG Amount to Invest': 121.18456402511596, 'HYG Shares to Buy': 2, 'HYG Shares After': 2.0, 'VGIT Desired Value': 60.59228201255798, 'VGIT Price': 57.689998626708984, 'VGIT Shares Before': 0.0, 'VGIT Total Value Before': 0.0, 'VGIT Amount to Invest': 60.59228201255798, 'VGIT Shares to Buy': 1, 'VGIT Shares After': 1.0, 'VIG Desired Value': 181.77684603767392, 'VIG Price': 161.39999389648438, 'VIG Shares Before': 0.0, 'VIG Total Value Before': 0.0, 'VIG Amount to Invest': 181.77684603767392, 'VIG Shares to Buy': 1, 'VIG Shares After': 1.0, 'VGT Desired Value': 1817.7684603767393, 'VGT Price': 436.25, 'VGT Shares Before': 0.0, 'VGT Total Value Before': 0.0, 'VGT Amount to Invest': 1817.7684603767393, 'VGT Shares to Buy': 4, 'VGT Shares After': 4.0, 'XLV Desired Value': 1800.1966985930974, 'XLV Price': 132.05999755859375, 'XLV Shares Before': 0.0, 'XLV Total Value Before': 0.0, 'XLV Amount to Invest': 1800.1966985930974, 'XLV Shares to Buy': 14, 'XLV Shares After': 14.0, 'ESGU Desired Value': 60.59228201255798, 'ESGU Price': 98.16999816894531, 'ESGU Shares Before': 0.0, 'ESGU Total Value Before': 0.0, 'ESGU Amount to Invest': 60.59228201255798, 'ESGU Shares to Buy': 1, 'ESGU Shares After': 1.0, 'VGK Desired Value': 0.0, 'VGK Price': 59.59000015258789, 'VGK Shares Before': 3.01, 'VGK Total Value Before': 179.36590045928955, 'VGK Amount to Invest': -179.36590045928955, 'VGK Shares to Buy': -3, 'VGK Shares After': 0.009999999999999787, 'VSS Desired Value': 0.0, 'VSS Price': 109.47000122070312, 'VSS Shares Before': 0.0, 'VSS Total Value Before': 0.0, 'VSS Amount to Invest': 0.0, 'VSS Shares to Buy': 0, 'VSS Shares After': 0.0, 'BSV Desired Value': 0.0, 'BSV Price': 75.30000305175781, 'BSV Shares Before': 1.0, 'BSV Total Value Before': 75.30000305175781, 'BSV Amount to Invest': -75.30000305175781, 'BSV Shares to Buy': -1, 'BSV Shares After': 0.0, 'VCSH Desired Value': 0.0, 'VCSH Price': 75.37000274658203, 'VCSH Shares Before': 5.02, 'VCSH Total Value Before': 378.3574137878418, 'VCSH Amount to Invest': -378.3574137878418, 'VCSH Shares to Buy': -5, 'VCSH Shares After': 0.019999999999999574}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(len(errors) == 0):\n",
        "\n",
        "    # Add TWD_USD_rate to the date_data dictionary\n",
        "    date_data['TWD_USD_rate'] = TWD_USD_rate\n",
        "\n",
        "    # Convert the dictionary to a DataFrame\n",
        "    df = pd.DataFrame(date_data)\n",
        "\n",
        "    # Switch the sign of 'Amount to Invest'\n",
        "    df['Amount to Invest'] = df['Amount to Invest'] * -1\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Check if the sheet exists\n",
        "    if 'ETF Prediction' in wb.sheetnames:\n",
        "        # If it exists, remove it\n",
        "        wb.remove(wb['ETF Prediction'])\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # For the ETF Prediction data\n",
        "    with pd.ExcelWriter('/content/drive/My Drive/Previous_ETF_Record.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        df.to_excel(writer, sheet_name='ETF Prediction', index=False)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Access the sheet\n",
        "    ws = wb['ETF Prediction']\n",
        "\n",
        "    # Iterate over the columns\n",
        "    for column in ws.columns:\n",
        "        max_length = 0\n",
        "        column = [cell for cell in column]\n",
        "        for cell in column:\n",
        "            try:\n",
        "                if len(str(cell.value)) > max_length:\n",
        "                    max_length = len(cell.value)\n",
        "            except:\n",
        "                pass\n",
        "        adjusted_width = (max_length + 2)\n",
        "        ws.column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    date_data_RE = best_date_data # calculate_difference.date_data\n",
        "    # Create a new DataFrame for the \"Shares To Buy\" data\n",
        "    shares_to_buy_data = {'Symbol': symbols_list}\n",
        "    shares_to_buy_data['Shares To Buy'] = [date_data_RE[f'{symbol} Shares to Buy'] for symbol in symbols_list]\n",
        "\n",
        "    df_shares_to_buy = pd.DataFrame(shares_to_buy_data)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Check if the sheet exists\n",
        "    if 'Shares To Buy' in wb.sheetnames:\n",
        "        # If it exists, remove it\n",
        "        wb.remove(wb['Shares To Buy'])\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Now you can write to the sheet\n",
        "    with pd.ExcelWriter('/content/drive/My Drive/Previous_ETF_Record.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        df_shares_to_buy.to_excel(writer, sheet_name='Shares To Buy', index=False)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Access the sheet\n",
        "    ws = wb['Shares To Buy']\n",
        "\n",
        "    # Iterate over the columns\n",
        "    for column in ws.columns:\n",
        "        max_length = 0\n",
        "        column = [cell for cell in column]\n",
        "        for cell in column:\n",
        "            try:\n",
        "                if len(str(cell.value)) > max_length:\n",
        "                    max_length = len(cell.value)\n",
        "            except:\n",
        "                pass\n",
        "        adjusted_width = (max_length + 2)\n",
        "        ws.column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')"
      ],
      "metadata": {
        "id": "zQhpWkFY_w5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(len(errors) == 0):\n",
        "\n",
        "    # Initialize an empty DataFrame to hold the value calculations\n",
        "    performance_data_1 = pd.DataFrame()\n",
        "    total_value_before_invest = []\n",
        "\n",
        "    # Iterate over each date\n",
        "\n",
        "    date = dates_list[-1]\n",
        "\n",
        "    # Initialize a dictionary to hold the calculations for this date\n",
        "    date_data = {'Date': date}\n",
        "    tem_total_before = 0\n",
        "    # Iterate over each ETF or Bond\n",
        "    for j in range(len(symbols_list)):\n",
        "        # Get the current symbol\n",
        "        symbol = symbols_list[j]\n",
        "\n",
        "        # Get the current price and number of shares to buy\n",
        "        price = price_data.loc[date, symbol]\n",
        "        shares_to_buy = date_data_RE[f'{symbol} Shares to Buy']  # Use date instead of i\n",
        "        shares_before = date_data_RE[f'{symbol} Shares Before']  # Use date instead of i\n",
        "\n",
        "        # Calculate the value\n",
        "        if symbol == '0050.TW':\n",
        "            value = shares_to_buy * price * -1\n",
        "            tem_total_before += (shares_before * price * 1)\n",
        "        else:\n",
        "            value = shares_to_buy * price * -1\n",
        "            tem_total_before += (shares_before * price)\n",
        "\n",
        "        # Add the value to the dictionary\n",
        "        date_data[f'{symbol} Performance'] = value\n",
        "    total_value_before_invest.append(tem_total_before)\n",
        "    # Add the dictionary to the DataFrame\n",
        "    performance_data_1 = pd.concat([performance_data_1, pd.DataFrame(date_data, index=[0])], ignore_index=True)\n",
        "\n",
        "    # Set the date as the index of the DataFrame\n",
        "    performance_data_1.set_index('Date', inplace=True)\n",
        "\n",
        "    invest_value = []\n",
        "\n",
        "    # Get the current date\n",
        "    date = dates_list[-1]\n",
        "\n",
        "    # Calculate the total value of all ETFs and bonds for this date\n",
        "    invest_value.append(performance_data_1.loc[date].sum())\n",
        "\n",
        "    performance_data_1.insert(len(performance_data_1.columns), 'Total Value', invest_value)\n",
        "    performance_data_1.insert(0, 'Amount Available', original_amount_available)\n",
        "    performance_data_1.insert(1, 'Total Value Before Invest', total_value_before_invest)\n",
        "\n",
        "    difference_list = []\n",
        "    within_range_list = []\n",
        "\n",
        "    # Calculate the difference and check if it's within the range\n",
        "    for i in range(len(performance_data_1)):\n",
        "        invest_value = performance_data_1.iloc[i, performance_data_1.columns.get_loc('Total Value')] * -1\n",
        "        amount_available = performance_data_1.iloc[i, performance_data_1.columns.get_loc('Amount Available')]\n",
        "        # difference = (invest_value - amount_available) / amount_available\n",
        "        difference = (invest_value - amount_available)\n",
        "        difference_list.append(difference)\n",
        "        within_range_list.append('Yes' if 0.05 >= difference >= -0.05 else 'No')\n",
        "\n",
        "    performance_data_1.insert(len(performance_data_1.columns), 'Difference', difference_list)\n",
        "    performance_data_1.insert(len(performance_data_1.columns), 'Within Range', within_range_list)\n",
        "\n",
        "    # Print the DataFrame to check\n",
        "    # print(performance_data_1)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Check if the sheet exists\n",
        "    if 'Performance' in wb.sheetnames:\n",
        "        # If it exists, remove it\n",
        "        wb.remove(wb['Performance'])\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Now you can write to the sheet\n",
        "    with pd.ExcelWriter('/content/drive/My Drive/Previous_ETF_Record.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        performance_data_1.to_excel(writer, sheet_name='Performance', index=False)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Access the sheet\n",
        "    ws = wb['Performance']\n",
        "\n",
        "    from openpyxl.styles import PatternFill\n",
        "\n",
        "    # Define a red fill\n",
        "    red_fill = PatternFill(start_color=\"FFFF0000\", end_color=\"FFFF0000\", fill_type=\"solid\")\n",
        "\n",
        "    # Iterate over the rows\n",
        "    for row in ws.iter_rows(min_row=2, min_col=ws.max_column - 1, max_col=ws.max_column):\n",
        "        for cell in row:\n",
        "            # If the cell value is 'No', fill it with red\n",
        "            if cell.value == 'No':\n",
        "                cell.fill = red_fill\n",
        "\n",
        "    # Iterate over the columns\n",
        "    for column in ws.columns:\n",
        "        max_length = 0\n",
        "        column = [cell for cell in column]\n",
        "        for cell in column:\n",
        "            try:\n",
        "                if len(str(cell.value)) > max_length:\n",
        "                    max_length = len(cell.value)\n",
        "            except:\n",
        "                pass\n",
        "        adjusted_width = (max_length + 2)\n",
        "        ws.column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "\n",
        "    # print(performance_data_1)\n",
        "\n",
        "\n",
        "    # print(df)"
      ],
      "metadata": {
        "id": "p1mOD4wG_ziU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(len(errors) == 0):\n",
        "\n",
        "    # Convert the dictionary to a DataFrame for ETF Prediction\n",
        "    # df_etf_prediction = pd.DataFrame(date_data)\n",
        "\n",
        "    # Create a new DataFrame for the \"Shares To Buy\" data\n",
        "    shares_to_buy_data = {'Symbol': symbols_list}\n",
        "    shares_to_buy_data['Shares To Buy'] = [date_data_RE[f'{symbol} Shares to Buy'] for symbol in symbols_list]\n",
        "    df_shares_to_buy = pd.DataFrame(shares_to_buy_data)\n",
        "\n",
        "    # Combine ETF Prediction and Performance data\n",
        "    combined_df = pd.concat([df, performance_data_1], axis=0, ignore_index=True)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Check if the combined sheet exists\n",
        "    if 'Extra Detail' in wb.sheetnames:\n",
        "        # If it exists, remove it\n",
        "        wb.remove(wb['Extra Detail'])\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Now you can write the combined data to the sheet\n",
        "    with pd.ExcelWriter('/content/drive/My Drive/Previous_ETF_Record.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        combined_df.to_excel(writer, sheet_name='Extra Detail', index=False)\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Access the sheet\n",
        "    ws = wb['Extra Detail']\n",
        "\n",
        "    # Iterate over the columns to adjust width\n",
        "    for column in ws.columns:\n",
        "        max_length = 0\n",
        "        column = [cell for cell in column]\n",
        "        for cell in column:\n",
        "            try:\n",
        "                if len(str(cell.value)) > max_length:\n",
        "                    max_length = len(cell.value)\n",
        "            except:\n",
        "                pass\n",
        "        adjusted_width = (max_length + 2)\n",
        "        ws.column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "    # Remove the original sheets\n",
        "    sheets_to_remove = ['ETF Prediction', 'Performance']\n",
        "    for sheet in sheets_to_remove:\n",
        "        if sheet in wb.sheetnames:\n",
        "            wb.remove(wb[sheet])\n",
        "\n",
        "    # Save the workbook\n",
        "    wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n"
      ],
      "metadata": {
        "id": "LELdxXQG_1SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if best_date_data is None\n",
        "if best_date_data is None:\n",
        "    shares_to_buy = [None] * len(symbols_list)\n",
        "    pre_txn_quantity = [None] * len(symbols_list)\n",
        "    unit_prices = [None] * len(symbols_list)\n",
        "    total_investment = None\n",
        "else:\n",
        "    shares_to_buy = [best_date_data[f'{symbol} Shares to Buy'] for symbol in symbols_list]\n",
        "    pre_txn_quantity = [best_date_data[f'{symbol} Shares Before'] for symbol in symbols_list]\n",
        "    unit_prices = [price_data.loc[dates_list[-1], symbol] for symbol in symbols_list]\n",
        "    total_investment = sum([best_date_data[f'{symbol} Shares to Buy'] * -1 * price for symbol, price in zip(symbols_list, unit_prices)])\n",
        "\n",
        "# Create a new DataFrame for the result presentation\n",
        "result_data = {\n",
        "    'Index': range(1, len(symbols_list) + 1),\n",
        "    'Symbol (input)': symbols_list,\n",
        "    'Weight Allocation': distribution,\n",
        "    'Pre-txn Quantity (交易前數量)': current_ETF_shares,\n",
        "    'Date & Time': [pd.to_datetime('today').strftime('%Y-%m-%d %H:%M:%S')] * len(symbols_list),\n",
        "    'Symbol (output)': symbols_list,\n",
        "    'Unit Price': unit_prices,\n",
        "    'Shares to 賣出-/買入+': shares_to_buy\n",
        "}\n",
        "\n",
        "df_result = pd.DataFrame(result_data)\n",
        "\n",
        "# Add the 'Investment Budget (USD) (賣出-/投資+)' column to the DataFrame\n",
        "# Only the first row contains the total investment, the rest are NaN\n",
        "df_result['Est. Investment Amt. (USD) (所得+ /付出-)'] = [total_investment] + [float('nan')] * (len(df_result) - 1)\n",
        "\n",
        "# Pad the errors list with empty strings to match the length of symbols_list\n",
        "if(len(errors) == 0):\n",
        "  # Add the 'Status' column.\n",
        "  df_result['Status'] = ['complete'] * (len(symbols_list) - len(errors))\n",
        "else:\n",
        "  errors += [''] * (len(symbols_list) - len(errors))\n",
        "  # Add the 'Status' column.\n",
        "  df_result['Status'] = errors\n",
        "\n",
        "# Load the workbook\n",
        "wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "# Check if the sheet \"auto re-balance output\" exists, if yes, remove it\n",
        "if 'auto re-balance output' in wb.sheetnames:\n",
        "    wb.remove(wb['auto re-balance output'])\n",
        "\n",
        "# Save the workbook\n",
        "wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "# Write the auto re-balance output data to the sheet\n",
        "with pd.ExcelWriter('/content/drive/My Drive/Previous_ETF_Record.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    df_result.to_excel(writer, sheet_name='auto re-balance output', index=False)\n",
        "\n",
        "# Load the workbook\n",
        "wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "# Access the sheet\n",
        "ws = wb['auto re-balance output']\n",
        "\n",
        "# Iterate over the columns to adjust column width\n",
        "for column in ws.columns:\n",
        "    max_length = 0\n",
        "    column = [cell for cell in column]\n",
        "    for cell in column:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(cell.value)\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = (max_length + 2)\n",
        "    ws.column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "# Save the workbook\n",
        "wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n"
      ],
      "metadata": {
        "id": "ZT3tLjVO_21b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wb = load_workbook('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n",
        "\n",
        "if errors:\n",
        "    # If there's an error, only keep 'auto-rebalance input' and 'auto-rebalance output' sheets\n",
        "    sheets_to_keep = ['auto re-balance input', 'auto re-balance output']\n",
        "    for sheet in wb.sheetnames:\n",
        "        if sheet not in sheets_to_keep:\n",
        "            wb.remove(wb[sheet])\n",
        "    center_content_in_sheet(wb, 'auto re-balance output')\n",
        "\n",
        "\n",
        "else:\n",
        "    # If there's no error, execute the original code\n",
        "    sheets_to_remove = ['ETF Prediction', 'Performance','Shares To Buy']\n",
        "    for sheet in sheets_to_remove:\n",
        "        if sheet in wb.sheetnames:\n",
        "            wb.remove(wb[sheet])\n",
        "\n",
        "    # Center the content of the sheet\n",
        "    center_content_in_sheet(wb, 'auto re-balance output')\n",
        "    center_content_in_sheet(wb, 'Extra Detail')\n",
        "\n",
        "    # Check if the sheets exist\n",
        "    if 'auto re-balance input' in wb.sheetnames and 'auto re-balance output' in wb.sheetnames and 'Extra Detail' in wb.sheetnames:\n",
        "        # Reorder the sheets\n",
        "        wb._sheets = [wb['auto re-balance input'], wb['auto re-balance output'], wb['Extra Detail']] + [s for s in wb._sheets if s.title not in ['auto re-balance input', 'auto re-balance output', 'Extra Detail']]\n",
        "\n",
        "# Save the workbook\n",
        "wb.save('/content/drive/My Drive/Previous_ETF_Record.xlsx')\n"
      ],
      "metadata": {
        "id": "6ZMgVRK3_4mL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}